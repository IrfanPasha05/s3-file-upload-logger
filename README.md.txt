# ğŸ“¦ AWS S3 File Upload Logger (Lambda + Python)

![AWS](https://img.shields.io/badge/AWS-Lambda-orange)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![Serverless](https://img.shields.io/badge/Serverless-Yes-success)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)

## ğŸš€ Project Overview

This project demonstrates an **event-driven serverless architecture** using AWS.  
Whenever a file is uploaded to an S3 bucket, an AWS Lambda function (Python) is automatically triggered to log file metadata such as:

- Bucket name  
- File name  
- File size  

The logs are stored and verified using **Amazon CloudWatch**.

---

User â†’ Upload File â†’ Amazon S3
â†“
Event Notification
â†“
AWS Lambda (Python)
â†“
CloudWatch Logs


---

## ğŸ› ï¸ Technologies Used

- AWS S3
- AWS Lambda (Python 3.11)
- AWS IAM
- Amazon CloudWatch
- Git & GitHub

---

## âš™ï¸ Lambda Function Logic

```python
bucket_name = record['s3']['bucket']['name']
file_name = record['s3']['object']['key']
file_size = record['s3']['object']['size']


The Lambda function extracts metadata from the S3 event and logs it.

New file uploaded to S3
Bucket Name: lambda-s3-demo-irfan
File Name: AI+Automation-in-excel.pdf
File Size: 192753 bytes

ğŸ” IAM Permissions Used

AmazonS3ReadOnlyAccess

CloudWatchLogsFullAccess

ğŸ“Œ Key Learnings

Event-driven serverless architecture

S3 â†’ Lambda triggers

IAM role-based access

CloudWatch monitoring & debugging

Real-time validation using file metadata

ğŸ§‘â€ğŸ’» Author

Irfan Pasha
Cloud & DevOps Enthusiast
ğŸ“ Bangalore, India

## ğŸ§  Architecture Flow

